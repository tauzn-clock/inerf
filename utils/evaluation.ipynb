{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from nerfstudio.utils.eval_utils import eval_setup\n",
    "from inerf.inerf_utils import load_eval_image_into_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspace')\n",
    "MODEL_PATH = \"/workspace/outputs/jackal_training_data_0/plane-nerf/2024-01-14_144644\"\n",
    "EVAL_PATH = \"/stored_data/jackal_evaluation_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">WARNING: Using slower TCNN CutlassMLP instead of TCNN FullyFusedMLP</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mWARNING: Using slower TCNN CutlassMLP instead of TCNN FullyFusedMLP\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Use layer width of </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">16</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">32</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">64</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">, or </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">128</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> to use the faster TCNN FullyFusedMLP.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mUse layer width of \u001b[0m\u001b[1;33m16\u001b[0m\u001b[1;33m, \u001b[0m\u001b[1;33m32\u001b[0m\u001b[1;33m, \u001b[0m\u001b[1;33m64\u001b[0m\u001b[1;33m, or \u001b[0m\u001b[1;33m128\u001b[0m\u001b[1;33m to use the faster TCNN FullyFusedMLP.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">WARNING: Using slower TCNN CutlassMLP instead of TCNN FullyFusedMLP</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mWARNING: Using slower TCNN CutlassMLP instead of TCNN FullyFusedMLP\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Use layer width of </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">16</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">32</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">64</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">, or </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">128</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> to use the faster TCNN FullyFusedMLP.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mUse layer width of \u001b[0m\u001b[1;33m16\u001b[0m\u001b[1;33m, \u001b[0m\u001b[1;33m32\u001b[0m\u001b[1;33m, \u001b[0m\u001b[1;33m64\u001b[0m\u001b[1;33m, or \u001b[0m\u001b[1;33m128\u001b[0m\u001b[1;33m to use the faster TCNN FullyFusedMLP.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n",
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n",
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n",
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading latest checkpoint from load_dir\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading latest checkpoint from load_dir\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Done loading checkpoint from \n",
       "outputs/jackal_training_data_0/plane-nerf/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-14_144644/nerfstudio_models/step-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000009999.</span>ckpt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Done loading checkpoint from \n",
       "outputs/jackal_training_data_0/plane-nerf/\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-14_144644/nerfstudio_models/step-\u001b[1;36m000009999.\u001b[0mckpt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_path = os.path.join(MODEL_PATH, \"config.yml\")\n",
    "config, pipeline, checkpoint_path, _ = eval_setup(\n",
    "                        Path(config_path),\n",
    "                        test_mode=\"inference\",\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/inerf/inerf/inerf_utils.py:97: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  camera_to_worlds = torch.cat([camera_to_worlds, tensor([tf]).float()], 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Setting up training dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Setting up training dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span> images.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Caching all \u001b[1;36m300\u001b[0m images.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cf4c67ae83429ba0c0313dde3036b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = load_eval_image_into_pipeline(pipeline,EVAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `spectral_angle_mapper` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `spectral_angle_mapper` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.8459096   0.62048922  0.56289135]\n"
     ]
    }
   ],
   "source": [
    "store_metrics = []\n",
    "for camera, batch in pipeline.datamanager.fixed_indices_train_dataloader:\n",
    "    outputs = pipeline.model.get_outputs_for_camera(camera=camera)\n",
    "    metrics_dict, images_dict = pipeline.model.get_image_metrics_and_images(outputs,batch)    \n",
    "    store_metrics.append([metrics_dict[\"psnr\"],metrics_dict[\"ssim\"],metrics_dict[\"lpips\"]])\n",
    "\n",
    "print(np.mean(store_metrics,axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/outputs/jackal_training_data_0/plane-nerf/2024-01-14_144644/metrics.csv\n"
     ]
    }
   ],
   "source": [
    "#Save store_metrics\n",
    "\n",
    "TARGET_PATH = os.path.join(MODEL_PATH, \"metrics.csv\")\n",
    "print(TARGET_PATH)\n",
    "np.savetxt(TARGET_PATH, store_metrics, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
